<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AI Mood Mirror</title>
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      margin: 20px;
    }
    #input-container {
      margin-top: 20px;
    }
    img {
      max-width: 300px;
    }
    canvas {
      position: absolute;
    }
  </style>
</head>
<body>
  <h1>Test Your AI Mood Mirror</h1>
  <p id="status">Loading model...</p>

  <div id="input-container">
    <input type="file" id="imageInput" accept="image/*">
    <p>Upload an image to detect faces</p>
    <img id="preview" src="" alt="Image Preview">
  </div>

  <div id="result">
    <h2>Prediction:</h2>
    <p id="prediction">Detecting faces...</p>
  </div>

  <script>
    // Load the face-api.js models from GitHub
    async function loadFaceApiModels() {
      await faceapi.nets.ssdMobilenetv1.loadFromUri('https://raw.githubusercontent.com/aimoodmirror/Gudoop/main/models');
      document.getElementById('status').innerText = 'Models loaded!';
    }

    loadFaceApiModels();

    // Handle image upload and face detection
    document.getElementById('imageInput').addEventListener('change', async (event) => {
      const file = event.target.files[0];
      if (!file) return;

      // Display the image preview
      const preview = document.getElementById('preview');
      preview.src = URL.createObjectURL(file);

      // Wait for the image to load
      preview.onload = async () => {
        // Create a canvas to draw the image on
        const canvas = faceapi.createCanvasFromMedia(preview);
        document.body.append(canvas);
        const displaySize = { width: preview.width, height: preview.height };
        faceapi.matchDimensions(canvas, displaySize);

        // Detect faces
        const detections = await faceapi.detectAllFaces(preview).withFaceLandmarks().withFaceDescriptors();

        // Display the detected faces
        const resizedDetections = faceapi.resizeResults(detections, displaySize);
        canvas?.clear();
        canvas?.drawDetections(resizedDetections);
        canvas?.drawFaceLandmarks(resizedDetections);
        canvas?.drawFaceDescriptors(resizedDetections);
        
        // Show how many faces are detected
        document.getElementById('prediction').innerText = `Faces detected: ${detections.length}`;
      };
    });
  </script>
</body>
</html>
